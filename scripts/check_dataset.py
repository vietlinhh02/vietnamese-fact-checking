"""
Script ki·ªÉm tra dataset ƒë√£ t·∫°o
"""

import json
import pandas as pd
from collections import Counter

def check_dataset(file_path):
    """Ki·ªÉm tra m·ªôt file dataset"""
    print(f"\n{'='*70}")
    print(f"Ki·ªÉm tra: {file_path}")
    print('='*70)
    
    # Load data
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line))
    
    df = pd.DataFrame(data)
    
    # Th·ªëng k√™ c∆° b·∫£n
    print(f"\nüìä Th·ªëng k√™:")
    print(f"  T·ªïng s·ªë samples: {len(df)}")
    print(f"\n  Ph√¢n b·ªë labels:")
    print(df['label'].value_counts().to_string().replace('\n', '\n  '))
    
    # ƒê·ªô d√†i text
    df['text_length'] = df['text'].str.len()
    df['word_count'] = df['text'].str.split().str.len()
    
    print(f"\n  ƒê·ªô d√†i text:")
    print(f"    - Trung b√¨nh: {df['text_length'].mean():.1f} chars")
    print(f"    - Min: {df['text_length'].min()} chars")
    print(f"    - Max: {df['text_length'].max()} chars")
    
    print(f"\n  S·ªë t·ª´:")
    print(f"    - Trung b√¨nh: {df['word_count'].mean():.1f} words")
    print(f"    - Min: {df['word_count'].min()} words")
    print(f"    - Max: {df['word_count'].max()} words")
    
    # Xem m·∫´u claims
    claims = df[df['label'] == 'claim']
    print(f"\n‚úÖ M·∫´u CLAIMS (5 samples):")
    for i, row in claims.head(5).iterrows():
        text = row['text']
        if len(text) > 100:
            text = text[:100] + "..."
        print(f"  {i+1}. {text}")
    
    # Xem m·∫´u non-claims
    non_claims = df[df['label'] == 'non-claim']
    print(f"\n‚ùå M·∫´u NON-CLAIMS (10 samples):")
    for i, row in non_claims.head(10).iterrows():
        print(f"  {i+1}. {row['text']}")
    
    # Ki·ªÉm tra duplicate
    duplicates = df[df.duplicated(subset=['text'], keep=False)]
    if len(duplicates) > 0:
        print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: C√≥ {len(duplicates)} duplicates!")
    else:
        print(f"\n‚úì Kh√¥ng c√≥ duplicates")
    
    # Ki·ªÉm tra empty
    empty = df[df['text'].str.strip() == '']
    if len(empty) > 0:
        print(f"‚ö†Ô∏è  C·∫£nh b√°o: C√≥ {len(empty)} empty texts!")
    else:
        print(f"‚úì Kh√¥ng c√≥ empty texts")
    
    return df

def main():
    print("="*70)
    print("KI·ªÇM TRA DATASET CLAIM DETECTION")
    print("="*70)
    
    files = [
        'data/claim_detection/claim_detection_train.jsonl',
        'data/claim_detection/claim_detection_val.jsonl',
        'data/claim_detection/claim_detection_test.jsonl'
    ]
    
    all_dfs = []
    for file_path in files:
        try:
            df = check_dataset(file_path)
            all_dfs.append(df)
        except Exception as e:
            print(f"\n‚úó Error: {e}")
    
    # T·ªïng k·∫øt
    print(f"\n{'='*70}")
    print("T·ªîNG K·∫æT")
    print('='*70)
    
    total_samples = sum(len(df) for df in all_dfs)
    total_claims = sum(len(df[df['label'] == 'claim']) for df in all_dfs)
    total_non_claims = sum(len(df[df['label'] == 'non-claim']) for df in all_dfs)
    
    print(f"\nüìä T·ªïng c·ªông:")
    print(f"  - Total: {total_samples:,} samples")
    print(f"  - Claims: {total_claims:,} ({total_claims/total_samples*100:.1f}%)")
    print(f"  - Non-claims: {total_non_claims:,} ({total_non_claims/total_samples*100:.1f}%)")
    
    print(f"\n‚úÖ ƒê√°nh gi√°:")
    
    # Ki·ªÉm tra c√¢n b·∫±ng
    balance_ratio = total_claims / total_non_claims
    if 0.9 <= balance_ratio <= 1.1:
        print(f"  ‚úì Dataset c√¢n b·∫±ng t·ªët (ratio: {balance_ratio:.2f})")
    else:
        print(f"  ‚ö†Ô∏è  Dataset kh√¥ng c√¢n b·∫±ng (ratio: {balance_ratio:.2f})")
    
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc
    if total_samples >= 10000:
        print(f"  ‚úì Dataset ƒë·ªß l·ªõn ({total_samples:,} samples)")
    else:
        print(f"  ‚ö†Ô∏è  Dataset nh·ªè ({total_samples:,} samples)")
    
    # Ki·ªÉm tra split
    train_size = len(all_dfs[0])
    val_size = len(all_dfs[1])
    test_size = len(all_dfs[2])
    
    train_ratio = train_size / total_samples
    val_ratio = val_size / total_samples
    test_ratio = test_size / total_samples
    
    print(f"\n  Split ratio:")
    print(f"    - Train: {train_ratio*100:.1f}% (expected: 70%)")
    print(f"    - Val: {val_ratio*100:.1f}% (expected: 15%)")
    print(f"    - Test: {test_ratio*100:.1f}% (expected: 15%)")
    
    if 0.68 <= train_ratio <= 0.72 and 0.13 <= val_ratio <= 0.17 and 0.13 <= test_ratio <= 0.17:
        print(f"  ‚úì Split ratio ƒë√∫ng")
    else:
        print(f"  ‚ö†Ô∏è  Split ratio kh√¥ng chu·∫©n")
    
    print(f"\n{'='*70}")
    print("‚úÖ KI·ªÇM TRA HO√ÄN T·∫§T!")
    print('='*70)

if __name__ == "__main__":
    main()
